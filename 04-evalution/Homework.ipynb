{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ace4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ea9a1",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77525315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..............................................................................] 73250 / 73250"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0  yes        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1  yes        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2  yes        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3  yes        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4  yes        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "\n",
       "   dependents  months  majorcards  active  \n",
       "0           3      54           1      12  \n",
       "1           3      34           1      13  \n",
       "2           4      58           1       5  \n",
       "3           0      25           1       7  \n",
       "4           2      64           1       5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv\")\n",
    "\n",
    "df = pd.read_csv('AER_credit_card_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4303bc08",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc059d6",
   "metadata": {},
   "source": [
    "- Create the target variable by mapping yes to 1 and no to 0.\n",
    "- Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split funciton for that with random_state=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81301bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0     1        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1     1        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2     1        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3     1        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4     1        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "\n",
       "   dependents  months  majorcards  active  \n",
       "0           3      54           1      12  \n",
       "1           3      34           1      13  \n",
       "2           4      58           1       5  \n",
       "3           0      25           1       7  \n",
       "4           2      64           1       5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy= df.copy()\n",
    "df['card']= df['card'].replace(\" \",\"\").replace(\"yes\",1).replace(\"no\",0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70084179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055 791 791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_split_data(data, seed, y_var_name):\n",
    "    df_full_train, df_test = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "    df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=seed)\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val = df_val.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    y_train = df_train[y_var_name].values\n",
    "    y_val = df_val[y_var_name].values\n",
    "    y_test = df_test[y_var_name].values\n",
    "\n",
    "    del df_train[y_var_name]\n",
    "    del df_val[y_var_name]\n",
    "    del df_test[y_var_name]\n",
    "    \n",
    "    return df_full_train, df_train, df_val, df_test, y_train, y_val, y_test\n",
    "\n",
    "df_full_train, df_train, df_val, df_test, y_train, y_val, y_test = get_split_data(df, 1, \"card\")\n",
    "print(len(df_full_train), len(df_train), len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98153c",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b6d43",
   "metadata": {},
   "source": [
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "- For each numerical variable, use it as score and compute AUC with the card variable.\n",
    "- Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "(e.g. -df_train['expenditure'])\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75399849",
   "metadata": {},
   "source": [
    "> share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4496f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reports, 0.717\n",
      "      age, 0.524\n",
      "   income, 0.591\n",
      "    share, 0.989\n",
      "expenditure, 0.991\n",
      "dependents, 0.533\n",
      "   months, 0.529\n",
      "majorcards, 0.534\n",
      "   active, 0.604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "numeric = ['reports', 'age', 'income', 'share', 'expenditure', 'dependents', 'months', 'majorcards', 'active']\n",
    "categorical = ['owner', 'selfemp']\n",
    "\n",
    "for n in numeric:\n",
    "    auc = roc_auc_score(y_train, df_train[n])\n",
    "    if auc < 0.5:\n",
    "        auc = roc_auc_score(y_train, -df_train[n])\n",
    "    print('%9s, %.3f' % (n, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b4347",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2da66",
   "metadata": {},
   "source": [
    "From now on, use these columns only:\n",
    "[\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a106cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 5.80231570e-02 1.00000000e+00 1.95534627e-02\n",
      " 1.00000000e+00 1.00000000e+00 7.01198813e-02 1.00000000e+00\n",
      " 1.00000000e+00 9.95731859e-01 1.38364919e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.38123515e-02\n",
      " 1.00000000e+00 1.00000000e+00 2.32127966e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 2.85316583e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.17336224e-08 4.51764762e-04 1.00000000e+00 4.44723877e-03\n",
      " 1.65674799e-05 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 4.81355783e-04 1.00000000e+00 1.00000000e+00\n",
      " 3.66674669e-03 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.71474282e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 4.42068328e-04\n",
      " 5.61144810e-02 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999406e-01 1.00000000e+00 9.99983226e-01\n",
      " 1.00000000e+00 1.00000000e+00 4.65458793e-03 1.70806364e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.25640574e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.39071067e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.85234954e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99907981e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.28329586e-01 1.00000000e+00 1.00000000e+00 3.02143311e-01\n",
      " 1.00000000e+00 2.45931633e-02 1.00000000e+00 1.00000000e+00\n",
      " 9.99965301e-01 1.00000000e+00 8.47847211e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 3.56047446e-02 3.71673811e-02 1.00000000e+00 1.00000000e+00\n",
      " 9.90828221e-01 1.00000000e+00 9.82882855e-02 1.00000000e+00\n",
      " 3.42046359e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.98901226e-01 2.59362840e-02 1.00000000e+00\n",
      " 1.38895778e-06 2.97627122e-01 1.55661350e-01 1.83649306e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 2.12449145e-02\n",
      " 1.00000000e+00 1.00000000e+00 2.74587600e-02 1.00000000e+00\n",
      " 5.88035203e-02 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 2.60381916e-03 1.00000000e+00 1.00000000e+00 1.21768658e-01\n",
      " 1.00000000e+00 9.62093641e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 2.20150900e-02 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 2.37187074e-02 9.90045140e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.26009101e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 3.33577646e-01 1.00000000e+00 5.67714948e-04\n",
      " 1.00000000e+00 1.00000000e+00 9.99986231e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99734788e-01 1.00000000e+00 1.00000000e+00 8.84074322e-03\n",
      " 1.00000000e+00 7.08023503e-02 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 5.31207502e-04 4.15690730e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.17820894e-07 1.00000000e+00 1.30691199e-01\n",
      " 1.00000000e+00 1.28277513e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999975e-01 1.00000000e+00 1.17656208e-02\n",
      " 9.95065347e-01 1.00000000e+00 9.98628907e-01 1.00000000e+00\n",
      " 4.03019267e-03 1.00000000e+00 2.85071328e-04 1.00000000e+00\n",
      " 9.99997766e-01 1.00000000e+00 1.00000000e+00 8.69564256e-03\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.36328877e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 2.40139254e-03 1.00000000e+00 1.52147655e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.22838558e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 2.54460369e-02 3.34786380e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00] [1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "cols= [\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# DataTrain one-hot encoding\n",
    "train_dicts = df_train[cols].to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# DataVal one-hot encoding\n",
    "val_dicts = df_val[cols].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "y_pred_bin = model.predict(X_val)\n",
    "\n",
    "print(y_pred, y_pred_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34f525",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce763c53",
   "metadata": {},
   "source": [
    "> 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61013590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995171242063847 0.9739783600107306\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
    "plt.plot(fpr, tpr, label='probability')\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_bin)\n",
    "plt.plot(fpr, tpr, label='hard prediction')\n",
    "\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "auc_bin = roc_auc_score(y_val, y_pred_bin)\n",
    "print(auc, auc_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81179b54",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "- Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "- For each threshold, compute precision and recall\n",
    "- Plot them\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "> 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f30c139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_dataframe(y_val, y_pred):\n",
    "    scores = []\n",
    "\n",
    "    thresholds = np.linspace(0, 1, 1001)\n",
    "\n",
    "    for t in thresholds:\n",
    "        actual_positive = (y_val == 1)\n",
    "        actual_negative = (y_val == 0)\n",
    "\n",
    "        predict_positive = (y_pred >= t)\n",
    "        predict_negative = (y_pred < t)\n",
    "\n",
    "        tp = (predict_positive & actual_positive).sum()\n",
    "        tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "        fp = (predict_positive & actual_negative).sum()\n",
    "        fn = (predict_negative & actual_positive).sum()\n",
    "\n",
    "        scores.append((t, tp, fp, fn, tn))\n",
    "\n",
    "    columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
    "    df_scores = pd.DataFrame(scores, columns=columns)\n",
    "    \n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d951cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.40</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.41</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.42</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.43</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.44</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.45</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.46</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.47</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.48</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.49</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.50</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.51</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.52</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0.53</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.54</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.55</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.56</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.57</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.58</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.59</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     threshold   tp  fp  fn  tn         p         r\n",
       "400       0.40  205   1   6  52  0.995146  0.971564\n",
       "410       0.41  205   1   6  52  0.995146  0.971564\n",
       "420       0.42  204   1   7  52  0.995122  0.966825\n",
       "430       0.43  204   1   7  52  0.995122  0.966825\n",
       "440       0.44  204   1   7  52  0.995122  0.966825\n",
       "450       0.45  204   1   7  52  0.995122  0.966825\n",
       "460       0.46  204   1   7  52  0.995122  0.966825\n",
       "470       0.47  204   1   7  52  0.995122  0.966825\n",
       "480       0.48  204   1   7  52  0.995122  0.966825\n",
       "490       0.49  204   1   7  52  0.995122  0.966825\n",
       "500       0.50  204   1   7  52  0.995122  0.966825\n",
       "510       0.51  204   1   7  52  0.995122  0.966825\n",
       "520       0.52  204   1   7  52  0.995122  0.966825\n",
       "530       0.53  204   1   7  52  0.995122  0.966825\n",
       "540       0.54  204   1   7  52  0.995122  0.966825\n",
       "550       0.55  204   1   7  52  0.995122  0.966825\n",
       "560       0.56  204   1   7  52  0.995122  0.966825\n",
       "570       0.57  204   1   7  52  0.995122  0.966825\n",
       "580       0.58  204   1   7  52  0.995122  0.966825\n",
       "590       0.59  204   1   7  52  0.995122  0.966825"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = confusion_matrix_dataframe(y_val, y_pred)\n",
    "df_scores['p'] = df_scores.tp / (df_scores.tp + df_scores.fp)\n",
    "df_scores['r'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
    "df_scores[400:600:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce247930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_scores.threshold, df_scores.p, label='precision')\n",
    "plt.plot(df_scores.threshold, df_scores.r, label='recall')\n",
    "\n",
    "plt.vlines(0.41, 0, 1, color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe800a1",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "F1 = 2 P R / (P + R)\n",
    "\n",
    "Where P is precision and R is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "> 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f17bdf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       0.888421\n",
       "100     0.958904\n",
       "200     0.978723\n",
       "300     0.973872\n",
       "400     0.983213\n",
       "500     0.980769\n",
       "600     0.980769\n",
       "700     0.980769\n",
       "800     0.980769\n",
       "900     0.983133\n",
       "1000    0.917949\n",
       "Name: f1, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores['f1'] = 2 * df_scores.p * df_scores.r / (df_scores.p + df_scores.r)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(df_scores.threshold, df_scores.f1)\n",
    "plt.vlines(0.7, 0, 1, color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xticks(np.linspace(0, 1, 11))\n",
    "plt.show()\n",
    "\n",
    "df_scores['f1'][::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b665af67",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "> KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "- Iterate over different folds of df_full_train\n",
    "- Split the data into train and validation\n",
    "- Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "- Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard devidation of the AUC scores across different folds?\n",
    "> 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b59697d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[cols].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return dv, model\n",
    "\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[cols].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be7cb995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.card.values\n",
    "    y_val = df_val.card.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=1.0)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print('%.3f +- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b9397",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "- Iterate over the following C values: [0.01, 0.1, 1, 10]\n",
    "- Initialize KFold with the same parameters as previously\n",
    "- Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "- Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "> 1\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6b5b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01, 0.992 +- 0.006\n",
      "C= 0.1, 0.995 +- 0.004\n",
      "C=   1, 0.996 +- 0.003\n",
      "C=  10, 0.996 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for C in [0.01, 0.1, 1, 10]:\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train.card.values\n",
    "        y_val = df_val.card.values\n",
    "\n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "\n",
    "    print('C=%4s, %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b609261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
